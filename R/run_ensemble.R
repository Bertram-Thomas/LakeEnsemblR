#' Run Ensemble of lake models
#'
#'Run each of the lake models
#'
#' @param config_file filepath; to LakeEnsemblr yaml master config file
#' @param model vector; model to export driving data. Options include c('GOTM', 'GLM', 'Simstrat', 'FLake')
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#' @param return_list boolean; Return a list of dataframes of model output. Defaults to FALSE
#' @import ncdf4
#' @importFrom FLakeR run_flake
#' @importFrom GLM3r run_glm
#' @importFrom GOTMr run_gotm
#' @importFrom SimstratR run_simstrat
#' @importFrom gotmtools get_yaml_value get_vari
#' @importFrom rLakeAnalyzer get.offsets
#' @importFrom reshape2 dcast
#' @importFrom glmtools get_nml_value get_var
#'
#' @export
run_ensemble <- function(config_file, model = c('GOTM', 'GLM', 'Simstrat', 'FLake'), folder = '.', return_list = FALSE){

  # It's advisable to set timezone to GMT in order to avoid errors when reading time
  original_tz = Sys.getenv("TZ")
  Sys.setenv(TZ="GMT")
  tz = 'UTC'

  # Set working directory
  oldwd <- getwd()

  # this way if the function exits for any reason, success or failure, these are reset:
  on.exit({
    setwd(oldwd)
    Sys.setenv(TZ=original_tz)
  })

  # Set all as NULL
  fla_out <- NULL
  glm_out <- NULL
  got_out <- NULL
  sim_out <- NULL
  obs_out <- NULL


  ## Extract start, stop, lat & lon for netCDF file from config file
  start <- get_yaml_value(config_file, "time", "start")
  stop <- get_yaml_value(config_file, "time", "stop")
  lat <- get_yaml_value(config_file, "location", "latitude")
  lon <- get_yaml_value(config_file, "location", "longitude")
  obs_file <- get_yaml_value(config_file, "observations", "file")

  # Get output configurations
  out_file <- get_yaml_value(config_file,"output", "file")
  out_depths <- get_yaml_value(config_file,"output", "depths")
  format <- get_yaml_value(config_file, "output", "format")
  time_method <- get_yaml_value(config_file, "output", "time_method")
  time_unit <- get_yaml_value(config_file, "output", "time_unit")
  time_step <- get_yaml_value(config_file, "output", "time_step")
  out_vars <- get_yaml_value(config_file, "output", "variables")

  if(format == 'netcdf'){
    create_netcdf = TRUE
    compression <- get_yaml_value(config_file, "output", "compression")
  }

  # Create output time vector
  out_time <- seq.POSIXt(as.POSIXct(start, tz = tz), as.POSIXct(stop, tz = tz), by = paste(time_step, time_unit))
  out_time <- data.frame(datetime = out_time)


  if(obs_file != 'NULL'){
    message('Loading obs_file...')
    obs <- read.csv(obs_file, stringsAsFactors = FALSE)
    obs_deps <- unique(obs$Depth_meter)

    # change data format from long to wide
    obs_out <- dcast(obs, datetime ~ Depth_meter, value.var = 'Water_Temperature_celsius')
    str_depths <- colnames(obs_out)[2:ncol(obs_out)]
    colnames(obs_out) <- c('datetime',paste('wtr_',str_depths, sep=""))
    obs_out$datetime <- as.POSIXct(obs_out$datetime, tz = tz)

    # Subset to out_time
    obs_out <- obs_out[obs_out$datetime %in% out_time$datetime,]
    obs_out <- merge(out_time, obs_out, by = 'datetime', all.x = TRUE)

  }else{
    obs_deps <- NULL
  }


  if('FLake' %in% model){

    #Need to figure out how to subset data by dates
    nml_file <- get_yaml_value(config_file, "config_files", "flake")
    nml_file <- file.path(folder, nml_file)
    if(file.exists(file.path(folder, 'FLake', 'all_meteo_file.dat'))){
      met_file <- file.path(folder, 'FLake', 'all_meteo_file.dat')
      met_outfile <- file.path(folder, 'FLake', 'meteo_file_tmp.dat')
    }else{
      met_file <- suppressWarnings(get_nml_value(arg_name = 'meteofile', nml_file = nml_file))
      met_file <- gsub(',','', met_file)
      met_file <- file.path(folder, 'FLake', met_file)
      met_outfile <- file.path(folder, 'FLake', met_file)
    }
    message('FLake: Loading ', met_file)
    met <- read.delim(met_file, header = FALSE, stringsAsFactors = F)
    colnames(met)[ncol(met)] <- 'datetime'
    met$datetime <- as.POSIXct(met$datetime, tz = tz)
    met_sub <- met[(met$datetime >= start & met$datetime <= stop),]
    if(nrow(met_sub) < nrow(met)){
      warning('FLake: Writing new met file with shorter time series: ', met_outfile)
    }
    met_sub[,1] <- 1:nrow(met_sub)

    # Write to file
    write.table(met_sub, met_outfile, sep = '\t', quote = FALSE, col.names = FALSE, row.names = FALSE)
    met_outfile <- basename(met_outfile)
    input_nml(nml_file, 'SIMULATION_PARAMS', 'time_step_number', nrow(met_sub))
    input_nml(nml_file, 'METEO', 'meteofile', paste0("'",met_outfile,"'"))

    # Select nml file again
    nml_file <- basename(get_yaml_value(config_file, "config_files", "flake"))
    run_flake(sim_folder = file.path(folder, 'FLake'), nml_file = nml_file)

    if(return_list | create_netcdf){
      # Extract output
      fold <- file.path(folder, 'FLake')
      nml_file <- file.path(folder, get_yaml_value(config_file, "config_files", "flake"))

      mean_depth <- suppressWarnings(get_nml_value(arg_name = 'depth_w_lk', nml_file = nml_file))
      depths <- seq(0, mean_depth, by = out_depths)

      # Add in obs depths which are not in depths and less than mean depth
      add_deps <- obs_deps[!(obs_deps %in% depths)]
      add_deps <- add_deps[which(add_deps < mean_depth)]
      depths <- c(add_deps, depths)
      depths <- depths[order(depths)]

      fla_out <- get_wtemp_df(output = file.path(folder, 'FLake', 'output', 'output.dat'), depths = depths, folder = fold, nml_file = nml_file)

      # Ensure FLake is on the same time step for output
      if(nrow(fla_out) != nrow(out_time)){
        fla_out <- merge(fla_out, out_time, by = 'datetime', all.y = T)
      }
    }

    message('FLake run is complete! ', paste0('[', Sys.time(),']'))
  }

  if('GLM' %in% model){

    #Need to input start and stop into nml file
    nml_file <- file.path(folder, get_yaml_value(config_file, "config_files", "glm"))
    input_nml(nml_file, label = 'time', key = 'start', value = paste0("'",start,"'"))
    input_nml(nml_file, label = 'time', key = 'stop', value = paste0("'",stop,"'"))

    # Update model output
    input_nml(nml_file, label = 'output', key = 'nsave', value = time_step)

    run_glm(sim_folder = file.path(folder, 'GLM'))

    message('GLM run is complete! ', paste0('[', Sys.time(),']'))

    if(return_list | create_netcdf){
      # Add in obs depths which are not in depths and less than mean depth
      depth <- suppressWarnings(get_nml_value(nml_file = file.path(folder, 'GLM', 'glm3.nml'), arg_name = 'lake_depth'))
      depths <- seq(0,depth, by = get_yaml_value(config_file,"output", "depths"))
      add_deps <- obs_deps[!(obs_deps %in% depths)]
      depths <- c(add_deps, depths)
      depths <- depths[order(depths)]
      # Extract output
      glm_out <- get_var(file = file.path(folder, 'GLM', 'output', 'output.nc'), var_name = 'temp', reference = 'surface', z_out = depths)
      colnames(glm_out) <- c('datetime',paste('wtr_', depths, sep=""))

      # Ensure GLM is on the same time step for output
      if(nrow(glm_out) != nrow(out_time)){
        glm_out <- merge(glm_out, out_time, by = 'datetime', all.y = T)
      }

    }

  }

  if('GOTM' %in% model){
    #Need to input start and stop into yaml file
    yaml_file <- file.path(folder, get_yaml_value(config_file, "config_files", "gotm"))
    input_yaml(yaml_file, label = 'time', key = 'start', value = start)
    input_yaml(yaml_file, label = 'time', key = 'stop', value = stop)

    #output yaml
    out_yaml <- file.path(folder, 'GOTM', 'output.yaml')
    input_yaml(out_yaml, label = 'output', key = 'time_method', value = time_method)
    input_yaml(out_yaml, label = 'output', key = 'time_unit', value = time_unit)
    input_yaml(out_yaml, label = 'output', key = 'time_step', value = time_step)
    input_yaml(out_yaml, label = 'output', key = 'format', value = 'netcdf')


    run_gotm(sim_folder = file.path(folder, 'GOTM'), yaml_file = basename(yaml_file))

    message('GOTM run is complete! ', paste0('[', Sys.time(),']'))

    if(return_list | create_netcdf){

      # Extract output
      temp <- get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'temp', print = FALSE)
      z <- get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'z', print = FALSE)

      # Add in obs depths which are not in depths and less than mean depth
      depths = seq(0, min(z[1,-1]), by = -1 * get_yaml_value(config_file,"output", "depths"))
      if(is.null(obs_deps)){
        obs_dep_neg <- NULL
      }else{
        obs_dep_neg <- -obs_deps
      }
      add_deps <- obs_dep_neg[!(obs_dep_neg %in% depths)]
      depths <- c(add_deps, depths)
      depths <- depths[order(-depths)]

      got_out <- setmodDepths(temp, z, depths = depths, print = T)

      got_out <- reshape2::dcast(got_out, date ~ depths)
      got_out <- got_out[,c(1,(ncol(got_out):2))]
      str_depths <- abs(as.numeric(colnames(got_out)[2:ncol(got_out)]))
      colnames(got_out) <- c('datetime',paste('wtr_',str_depths, sep=""))

      # Ensure GOTM is on the same time step for output
      if(nrow(got_out) != nrow(out_time)){
        got_out <- merge(got_out, out_time, by = 'datetime', all.y = T)
      }
    }

  }

  if('Simstrat' %in% model){

    # Need to input start and stop into json par file
    par_file <- basename(get_yaml_value(config_file, "config_files", "simstrat"))

    run_simstrat(sim_folder = file.path(folder, 'Simstrat'), par_file = par_file, verbose = FALSE)

    message('Simstrat run is complete! ', paste0('[', Sys.time(),']'))

    if(return_list | create_netcdf){

      ### Extract output
      sim_out <- read.table(file.path(folder, "Simstrat", "output", "T_out.dat"), header = T, sep=",", check.names = F)

      ### Convert decimal days to yyyy-mm-dd HH:MM:SS
      par_file <- file.path(folder, get_yaml_value(config_file, "config_files", "simstrat"))
      timestep <- get_json_value(par_file, "Simulation", "Timestep s")
      reference_year <- get_json_value(par_file, "Simulation", "Start year")

      sim_out[,1] <- as.POSIXct(sim_out[,1]*3600*24, origin = start)
      # In case sub-hourly time steps are used, rounding might be necessary
      sim_out[,1] <- lubridate::round_date(sim_out[,1], unit = lubridate::seconds_to_period(timestep))

      # First column datetime, then depth from shallow to deep
      sim_out <- sim_out[,c(1,ncol(sim_out):2)]

      # Remove columns without any value
      sim_out <- sim_out[,colSums(is.na(sim_out))<nrow(sim_out)]

      # Add in obs depths which are not in depths and less than mean depth
      mod_depths = as.numeric(colnames(sim_out)[-1])
      if(is.null(obs_deps)){
        obs_dep_neg <- NULL
      }else{
        obs_dep_neg <- -obs_deps
      }
      add_deps <- obs_dep_neg[!(obs_dep_neg %in% mod_depths)]
      depths <- c(add_deps, mod_depths)
      depths <- depths[order(-depths)]

      if(length(depths) != (ncol(sim_out)-1)){
        message('Interpolating Simstrat temp to include obs depths')

        # Create empty matrix and interpolate to new depths
        wat_mat <- matrix(NA, nrow = nrow(sim_out), ncol = length(depths))
        for(i in 1:nrow(sim_out)){
          y = as.vector(unlist(sim_out[i,-1]))
          wat_mat[i,] <- approx(mod_depths, y, depths, rule = 2)$y
        }
        df = data.frame(wat_mat)
        df$datetime <- sim_out[,1]
        df <- df[,c(ncol(df), 1:(ncol(df)-1))]
        colnames(df) <- c("datetime", paste0('wtr_',abs(depths)))
        sim_out <- df
      }else{
        # Set column headers
        str_depths <- abs(as.numeric(colnames(sim_out)[2:ncol(sim_out)]))
        colnames(sim_out) <- c("datetime", paste0('wtr_',str_depths))
      }
      # Ensure Simstrat is on the same time step for output
      if(nrow(sim_out) != nrow(out_time)){
        sim_out <- merge(sim_out, out_time, by = 'datetime', all.y = T)
      }
    }
  }

  if(return_list | create_netcdf){

    temp_list = list('FLake' = fla_out, 'GLM' = glm_out, 'GOTM' = got_out, 'Simstrat' = sim_out, 'Obs' = obs_out)

    if(create_netcdf){

      temp_list <- Filter(Negate(is.null), temp_list) # Remove NULL outputa
      # mods <- names(temp_list) # Store names as a vector
      # lengths <- lapply(temp_list, nrow) # Extract nrows in each output
      # lon_list <- which.max(lengths[1:(length(lengths)-1)]) # Select largest time
      # time <- temp_list[[lon_list]][,1]  # Extract largest time as vector
      # # Loop through and merge dataframes by time
      # temp_list <- lapply(1:length(temp_list), function(x){
      #   if(x == lon_list){
      #     return(temp_list[[x]])
      #   }else{
      #     merge(data.frame(time = time),temp_list[[x]], by = 1, all.x = T)
      #   }
      #   })
      # names(temp_list) <- mods # Re-assign names to list


      lengths <- lapply(temp_list, ncol) # Extract ncols in each output
      lon_list <- which.max(lengths) # Select largest depths
      deps <- get.offsets(temp_list[[lon_list]]) # Extract depths
      deps <- deps

      # Creat output directory
      message('Creating directory for output: ', file.path(folder, 'output'))
      dir.create(file.path(folder, 'output'), showWarnings = FALSE)

      #Create ncdf
      message('Creating NetCDF file [', Sys.time(), ']')
      ref_time <- as.POSIXct('1970-01-01 00:00:00', tz = 'GMT') # Reference time for netCDF time
      nsecs <- as.numeric(difftime(out_time$datetime, ref_time, units = 'secs')) # Calculate seconds since reference time
      xvals <- 180 - lon # Convert longitude to degrees east
      yvals <- lat # Latitude
      # Define lon and lat dimensions
      lon1 <- ncdim_def("lon", "degrees_east", vals = as.double(xvals))
      lat2 <- ncdim_def("lat", "degrees_north", vals = as.double(yvals))

      #Set dimensions
      depthdim <- ncdim_def("z",units = "meters",vals = as.double(rev(deps)), longname = 'Depth from surface') # Depth dimension
      timedim <- ncdim_def("time",units = 'seconds since 1970-01-01 00:00:00', vals = as.double(nsecs), calendar = 'proleptic_gregorian') # Time dimension

      fillvalue <- 1e20 # Fill value
      missvalue <- 1e20 # Missing value

      nc_vars <- list() #Initialize empty list to fill netcdf variables
      for(i in 1:length(temp_list)){
        lname <- paste(names(temp_list)[i],'Water temperature') # Long name
        tmp_def <- ncvar_def(paste0(tolower(names(temp_list)[i]), "_watertemp"), "Celsius", list(lon1, lat2, timedim,depthdim), fillvalue, lname, prec="float", compression = compression, shuffle = FALSE) # Define variable
        nc_vars[[i]] <- tmp_def # Add to list
      }
      names(nc_vars) <- names(temp_list) # Re-assign list names

      fname = file.path(folder, 'output', out_file) # Ensemble output

      # Create and input data into the netCDF file
      ncout <- nc_create(fname, nc_vars, force_v4 = T)
      # Add coordinates attribute for use with get_vari()
      ncatt_put(ncout, 'z', attname = 'coordinates', attval = c('z'))

      # Loop through and add each variable

      # Add tryCatch ensure that it closes netCDF file
      result <- tryCatch({
        for(i in 1:length(temp_list)){
          mat1 <- matrix(NA, nrow = nc_vars[[i]]$dim[[3]]$len, ncol = nc_vars[[i]]$dim[[4]]$len)

          deps_temp <- get.offsets(temp_list[[i]]) # vector of depths to input into the matrix
          mat <- as.matrix(temp_list[[i]][,-1])

          for(j in 1:ncol(mat)){
            col = which(deps == deps_temp[j])
            mat1[,col] <- mat[,j]
          }
          # mat1[1:nrow(mat),1:ncol(mat)] <- mat

          ncvar_put(ncout, nc_vars[[i]], mat1)
          ncatt_put(ncout, nc_vars[[i]], attname = 'coordinates', attval = c('lon lat z'))
          ncvar_change_missval(ncout, nc_vars[[i]], missval = fillvalue)
        }
      }, warning = function(w) {
        return_val = 'Warning'
      }, error = function(e) {
        return_val = 'Error'
        warning('Error creating netCDF file!')
      }, finally = {
        nc_close(ncout) # Close netCDF file
      })

      message('Finished writing NetCDF file [', Sys.time(), ']')

    }


  }

  # Set the timezone back to the original
  Sys.setenv(TZ=original_tz)

  if(return_list){
    return(temp_list)
  }
}
