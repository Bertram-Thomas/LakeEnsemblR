#' Run Ensemble of lake models
#'@description
#'Run each of the lake models
#'
#' @name run_ensemble
#' @param model vector; model to export driving data. Options include c('GOTM', 'GLM', 'Simstrat', 'FLake')
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#' @param return_list boolean; Return a list of dataframes of model output. Deafults to FALSE
#' @param config_file filepath; to LakeEnsemblr yaml config file. Not active yet!
#' 
#' @example 
#' 
#' @import ncdf4, lubridate
#' 
#' @export
run_ensemble <- function(model = c('GOTM', 'GLM', 'Simstrat', 'FLake'), folder = '.', return_list = FALSE, make_output = TRUE, config_file = NULL){
  
  # Set all as NULL
  fla_out <- NULL
  glm_out <- NULL
  got_out <- NULL
  sim_out <- NULL
  
  # It's advisable to set timezone to GMT in order to avoid errors when reading time
  original_tz = Sys.getenv("tz")
  Sys.setenv(tz="GMT")
  
  ## Extract start, stop, lat & lon for netCDF file from config file
  start = '1979-01-01 00:00:00'
  stop = '1980-01-01 00:00:00'
  lat <- 53
  lon <- 9
  
  if('FLake' %in% model){
    #Need to figure out how to subset data by dates
    nml_file <- list.files(file.path(folder, 'FLake'))[grep('nml', list.files(file.path(folder, 'FLake')))]
    nml_file <- file.path(folder, 'FLake', nml_file)
    met_file <- glmtools::get_nml_value(arg_name = 'meteofile', nml_file = nml_file)
    met_file <- gsub(',','', met_file)
    met_file <- file.path(folder, 'FLake', met_file)
    met <- read.delim(met_file, header = FALSE, stringsAsFactors = F)
    colnames(met)[ncol(met)] <- 'datetime'
    met$datetime <- as.POSIXct(met$datetime)
    met_sub <- met[(met$datetime >= start & met$datetime <= stop),]
    if(nrow(met_sub) < nrow(met)){
      warning('Overwriting met file with shorter time series')
    }
    
    # Write to file
    write.table(met_sub, met_file, sep = '\t', quote = FALSE, col.names = FALSE, row.names = FALSE)
    input_nml(nml_file, 'SIMULATION_PARAMS', 'time_step_number', nrow(met_sub))
    
    # Select nml file again
    nml_file <- list.files(file.path(folder, 'FLake'))[grep('nml', list.files(file.path(folder, 'FLake')))]
    run_flake(sim_folder = file.path(folder, 'FLake'), nml_file = nml_file)
    
    if(return_list | make_output){
      # Extract output
      fold <- file.path(folder, 'FLake')
      nml_file <- file.path(folder, 'FLake', nml_file)
      
      fla_out <- get_wtemp_df(output = file.path(folder, 'FLake', 'output', 'output.dat'), folder = 'FLake', nml_file = nml_file)
    }
    
    message('FLake run is complete! ', paste0('[', Sys.time(),']'))
  }
  
  if('GLM' %in% model){
    #Need to input start and stop into nml file
    nml_file <- list.files(file.path(folder, 'GLM'))[grep('nml', list.files(file.path(folder, 'GLM')))]
    nml_file <- file.path(folder, 'GLM', nml_file)
    input_nml(nml_file, label = 'time', key = 'start', value = paste0("'",start,"'"))
    input_nml(nml_file, label = 'time', key = 'stop', value = paste0("'",stop,"'"))
    
    run_glm(sim_folder = file.path(folder, 'GLM'))
    
    message('GLM run is complete! ', paste0('[', Sys.time(),']'))
    
    if(return_list | make_output){
      # Extract output
      depth <- glmtools::get_nml_value(nml_file = file.path(folder, 'GLM', 'glm3.nml'), arg_name = 'lake_depth')
      glm_out <- glmtools::get_var(file = file.path(folder, 'GLM', 'output', 'output.nc'), var_name = 'temp', reference = 'surface', z_out = seq(0,depth, by = 0.5))
    }
    
  }
  
  if('GOTM' %in% model){
    #Need to input start and stop into yaml file
    yaml_file <- file.path(folder, 'GOTM', 'gotm.yaml')
    input_yaml(yaml_file, label = 'time', key = 'start', value = start)
    input_yaml(yaml_file, label = 'time', key = 'stop', value = stop)
    
    # Extract lat & lon for netCDF file
    
    run_gotm(sim_folder = file.path(folder, 'GOTM'))
    
    message('GOTM run is complete! ', paste0('[', Sys.time(),']'))
    
    if(return_list | make_output){
      
      # Extract output
      temp <- gotmtools::get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'temp', print = FALSE)
      z <- gotmtools::get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'z', print = FALSE)
      got_out <- setmodDepths(temp, z, depths = seq(0, min(z[1,-1]), by = -0.5), print = T)
      
      got_out <- reshape2::dcast(got_out, date ~ depths)
      got_out <- got_out[,c(1,(ncol(got_out):2))]
      str_depths <- abs(as.numeric(colnames(got_out)[2:ncol(got_out)]))
      colnames(got_out) <- c('datetime',paste('wtr_',str_depths, sep=""))
    }
    
  }
  
  if('Simstrat' %in% model){
    # Need to input start and stop into json par file
    par_file <- list.files(file.path(folder, 'Simstrat'))[grep('par', list.files(file.path(folder, 'Simstrat')))]
    par_file <- file.path(folder, 'Simstrat', par_file)
    
    reference_year <- get_json_value(par_file, "Simulation", "Start year")
    start_date_simulation <- lubridate::floor_date(as.POSIXct(start), unit = "days")
    end_date_simulation <- lubridate::ceiling_date(as.POSIXct(stop), unit = "days")
    input_json(par_file, "Simulation", "Start d", round(as.numeric(difftime(start_date_simulation, as.POSIXct(paste0(reference_year,"-01-01")), units = "days"))))
    input_json(par_file, "Simulation", "End d", round(as.numeric(difftime(end_date_simulation, as.POSIXct(paste0(reference_year,"-01-01")), units = "days"))))
    
    fils <- list.files('Simstrat/')
    par_file <- fils[grep('par', fils)]
    
    run_simstrat(sim_folder = file.path(folder, 'Simstrat'), par_file = par_file, verbose = FALSE)
    
    message('Simstrat run is complete! ', paste0('[', Sys.time(),']'))
    
    if(return_list | make_output){
      ### Extract output
      sim_out <- read.table(file.path(folder, "Simstrat", "output", "T_out.dat"), header = T, sep=",", check.names = F)
      
      ### Convert decimal days to yyyy-mm-dd HH:MM:SS
      par_file <- file.path(folder, 'Simstrat', par_file)
      timestep <- get_json_value(par_file, "Simulation", "Timestep s")
      
      sim_out[,1] <- as.POSIXct(sim_out[,1]*3600*24, origin = paste0(reference_year,"-01-01"))
      # In case sub-hourly time steps are used, rounding might be necessary
      sim_out[,1] <- lubridate::round_date(sim_out[,1], unit = lubridate::seconds_to_period(timestep))
      
      # First column datetime, then depth from shallow to deep
      sim_out <- sim_out[,c(1,ncol(sim_out):2)]
      
      # Remove columns without any value
      sim_out <- sim_out[,colSums(is.na(sim_out))<nrow(sim_out)]
      
      # Set column headers
      str_depths <- abs(as.numeric(colnames(sim_out)[2:ncol(sim_out)]))
      colnames(sim_out) <- c("datetime", paste0('wtr_',str_depths))
      
    }
  }
  
  if(return_list | make_output){
    
    temp_list = list('FLake' = fla_out, 'GLM' = glm_out, 'GOTM' = got_out, 'Simstrat' = sim_out)
    
    if(make_output){
      
      temp_list <- Filter(Negate(is.null), temp_list) # Remove NULL outputa
      mods <- names(temp_list) # Store names as a vector
      lengths <- lapply(temp_list, nrow) # Extract nrows in each output
      lon_list <- which.max(lengths) # Select largest time
      time <- temp_list[[lon_list]][,1]  # Extract largest time as vector
      # Loop through and merge dataframes by time
      temp_list <- lapply(1:length(temp_list), function(x){ 
        if(x == lon_list){
          return(temp_list[[x]])
        }else{
          merge(data.frame(time = time),temp_list[[x]], by = 1, all.x = T)
        }
        })
      names(temp_list) <- mods # Re-assign names to list
      
      
      lengths <- lapply(temp_list, ncol) # Extract ncols in each output
      lon_list <- which.max(lengths) # Select largest depths
      deps <- rLakeAnalyzer::get.offsets(temp_list[[lon_list]]) # Extract depths
      
      #Create ncdf
      message('Creating NetCDF file [', Sys.time(), ']')
      ref_time <- as.POSIXct('1970-01-01 00:00:00', tz = 'GMT') # Reference time for netCDF time
      nsecs <- as.numeric(difftime(time, ref_time, units = 'secs')) # Calculate seconds since reference time
      xvals <- 180 - lon # Convert longitude to degrees east
      yvals <- lat # Latitude
      # Define lon and lat dimensions
      lon1 <- ncdim_def("lon", "degrees_east", vals = as.double(xvals))
      lat2 <- ncdim_def("lat", "degrees_north", vals = as.double(yvals))
      
      #Set dimensions
      depthdim <- ncdim_def("z",units = "meters",vals = as.double(rev(deps)), longname = 'Depth from surface') # Depth dimension
      timedim <- ncdim_def("time",units = 'seconds since 1970-01-01 00:00:00', vals = as.double(nsecs), calendar = 'proleptic_gregorian') # Time dimension
      
      fillvalue <- 1e20 # Fill value
      missvalue <- 1e20 # Missing value
      
      nc_vars <- list() #Initialize empty list to fill netcdf variables
      for(i in 1:length(temp_list)){
        lname <- paste(names(temp_list)[i],'Water temperature') # Long name
        tmp_def <- ncvar_def(paste0(tolower(names(temp_list)[i]), "_watertemp"), "Celsius", list(lon1, lat2, timedim,depthdim), fillvalue, lname, prec="float", compression = 4, shuffle = FALSE) # Define variable
        nc_vars[[i]] <- tmp_def # Add to list
      }
      names(nc_vars) <- names(temp_list) # Re-assign list names
      
      fname ='ensemble_output.nc4' # Ensemble output
     
      # Create and input data into the netCDF file
      ncout <- nc_create(fname, nc_vars, force_v4 = T)
      # Add coordinates attribute for use with gotmtools::get_vari()
      ncatt_put(ncout, 'z', attname = 'coordinates', attval = c('z'))
      
      # Loop through and add each variable
      
      # Add tryCatch ensure that it closes netCDF file
      result <- tryCatch({
        for(i in 1:length(temp_list)){
          mat1 <- matrix(NA, nrow = nc_vars[[i]]$dim[[3]]$len, ncol = nc_vars[[i]]$dim[[4]]$len)
          
          mat <- as.matrix(temp_list[[i]][,-1])
          
          mat1[1:nrow(mat),1:ncol(mat)] <- mat
          ncvar_put(ncout, nc_vars[[i]], mat1)
          ncatt_put(ncout, nc_vars[[i]], attname = 'coordinates', attval = c('lon lat z'))
          ncvar_change_missval(ncout, nc_vars[[i]], missval = fillvalue)
        }
      }, warning = function(w) {
        return_val = 'Warning'
      }, error = function(e) {
        return_val = 'Error'
        message('Error creating netCDF file!')
      }, finally = {
        nc_close(ncout) # Close netCDF file
      })
      
      
      # for(i in 1:length(temp_list)){
      #   mat1 <- matrix(NA, nrow = nc_vars[[i]]$dim[[3]]$len, ncol = nc_vars[[i]]$dim[[4]]$len)
      #   
      #   mat <- as.matrix(temp_list[[i]][,-1])
      #   
      #   mat1[1:nrow(mat),1:ncol(mat)] <- mat
      #   ncvar_put(ncout, nc_vars[[i]], mat1)
      #   ncatt_put(ncout, nc_vars[[i]], attname = 'coordinates', attval = c('lon lat z'))
      #   ncvar_change_missval(ncout, nc_vars[[i]], missval = fillvalue)
      # }
      # nc_close(ncout) # Close netCDF file
      
      message('Finished writing NetCDF file [', Sys.time(), ']')
      
    }
    
    
  }
  
  # Set the timezone back to the original
  Sys.setenv(tz=original_tz)
  
  if(return_list){
    return(temp_list)
  }
}
