#' Run Ensemble of lake models
#'@description
#'Run each of the lake models
#'
#' @name run_ensemble
#' @param model vector; model to export driving data. Options include c('GOTM', 'GLM', 'Simstrat', 'FLake')
#' @param folder filepath; to folder which contains the model folders generated by export_config()
#' @param return_list boolean; Return a list of dataframes of model output. Deafults to FALSE
#' @param start character; Model start time in the format of 'YYYY-mm-dd HH:MM:SS
#' @param stop character; Model stop time in the format of 'YYYY-mm-dd HH:MM:SS
#' 
#' @example 
#' 
#' @import ncdf4
#' 
#' @export
run_ensemble <- function(model = c('GOTM', 'GLM', 'Simstrat', 'FLake'), folder = '.', return_list = FALSE, make_output = TRUE, start = NULL, stop = NULL){
  
  # Set all as NULL
  fla_out <- NULL
  glm_out <- NULL
  got_out <- NULL
  sim_out <- NULL
  
  # It's advisable to set timezone to GMT in order to avoid errors when reading time
  original_tz = Sys.getenv("tz")
  Sys.setenv(tz="GMT")
  
  # Extract lat & lon for netCDF file from config file
  lat <- 53
  lon <- 9
  
  if('FLake' %in% model){
    #Need to figure out how to subset data by dates
    
    # Find nml file
    nml_file <- list.files(file.path(folder, 'FLake'))[grep('nml', list.files(file.path(folder, 'FLake')))]
    
    run_flake(sim_folder = file.path(folder, 'FLake'), nml_file = nml_file)
    
    if(return_list | make_output){
      # Extract output
      fold <- file.path(folder, 'FLake')
      nml_file <- file.path(folder, 'FLake', nml_file)
      
      fla_out <- get_wtemp_df(output = file.path(folder, 'FLake', 'output', 'output.dat'), folder = 'FLake', nml_file = nml_file)
    }
    
    message('FLake run is complete! ', paste0('[', Sys.time(),']'))
  }
  
  if('GLM' %in% model){
    #Need to input start and stop into nml file
    
    run_glm(sim_folder = file.path(folder, 'GLM'))
    
    message('GLM run is complete! ', paste0('[', Sys.time(),']'))
    
    if(return_list | make_output){
      # Extract output
      depth <- glmtools::get_nml_value(nml_file = file.path(folder, 'GLM', 'glm3.nml'), arg_name = 'lake_depth')
      glm_out <- glmtools::get_var(file = file.path(folder, 'GLM', 'output', 'output.nc'), var_name = 'temp', reference = 'surface', z_out = seq(0,depth, by = 0.5))
    }
    
  }
  
  if('GOTM' %in% model){
    #Need to input start and stop into yaml file
    
    # Extract lat & lon for netCDF file
    
    run_gotm(sim_folder = file.path(folder, 'GOTM'))
    
    message('GOTM run is complete! ', paste0('[', Sys.time(),']'))
    
    if(return_list | make_output){
      
      # Extract output
      temp <- gotmtools::get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'temp', print = FALSE)
      z <- gotmtools::get_vari(ncdf = file.path(folder, 'GOTM', 'output', 'output.nc'), var = 'z', print = FALSE)
      got_out <- setmodDepths(temp, z, depths = seq(0, min(z[1,-1]), by = -0.5), print = T)
      
      got_out <- reshape2::dcast(got_out, date ~ depths)
      got_out <- got_out[,c(1,(ncol(got_out):2))]
      str_depths <- abs(as.numeric(colnames(got_out)[2:ncol(got_out)]))
      colnames(got_out) <- c('datetime',paste('wtr_',str_depths, sep=""))
    }
    
  }
  
  if('Simstrat' %in% model){
    # Need to input start and stop into json par file
    
    fils <- list.files('Simstrat/')
    par_file <- fils[grep('par', fils)]
    
    run_simstrat(sim_folder = file.path(folder, 'Simstrat'), par_file = par_file, verbose = FALSE)
    
    message('Simstrat run is complete! ', paste0('[', Sys.time(),']'))
    
    if(return_list | make_output){
      # Input functions to extrat Simstrat output and format for rLake Analyzer
      
    }
    
  }
  
  if(return_list | make_output){
    
    temp_list = list('FLake' = fla_out, 'GLM' = glm_out, 'GOTM' = got_out, 'Simstrat' = sim_out)
    
    if(make_output){
      
      temp_list <- Filter(Negate(is.null), temp_list) # Remove NULL outputa
      mods <- names(temp_list) # Store names as a vector
      lengths <- lapply(temp_list, nrow) # Extract nrows in each output
      lon_list <- which.max(lengths) # Select largest time
      time <- temp_list[[lon_list]][,1]  # Extract largest time as vector
      # Loop through and merge dataframes by time
      temp_list <- lapply(1:length(temp_list), function(x){ 
        if(x == lon_list){
          return(temp_list[[x]])
        }else{
          merge(data.frame(time = time),temp_list[[x]], by = 1, all.x = T)
        }
        })
      names(temp_list) <- mods # Re-assign names to list
      
      
      lengths <- lapply(temp_list, ncol) # Extract ncols in each output
      lon_list <- which.max(lengths) # Select largest depths
      deps <- rLakeAnalyzer::get.offsets(temp_list[[lon_list]]) # Extract depths
      
      #Create ncdf
      message('Creating NetCDF file [', Sys.time(), ']')
      ref_time <- as.POSIXct('1970-01-01 00:00:00', tz = 'GMT') # Reference time for netCDF time
      nsecs <- as.numeric(difftime(time, ref_time, units = 'secs')) # Calculate seconds since reference time
      xvals <- 180 - lon # Convert longitude to degrees east
      yvals <- lat # Latitude
      # Define lon and lat dimensions
      lon1 <- ncdim_def("lon", "degrees_east", vals = as.double(xvals))
      lat2 <- ncdim_def("lat", "degrees_north", vals = as.double(yvals))
      
      #Set dimensions
      depthdim <- ncdim_def("z",units = "meters",vals = as.double(deps), longname = 'Depth from surface') # Depth dimension
      timedim <- ncdim_def("time",units = 'seconds since 1970-01-01 00:00:00', vals = as.double(nsecs), calendar = 'proleptic_gregorian') # Time dimension
      
      fillvalue <- 1e20 # Fill value
      missvalue <- 1e20 # Missing value
      
      nc_vars <- list() #Initialize empty list to fill netcdf variables
      for(i in 1:length(temp_list)){
        lname <- paste(names(temp_list)[i],'Water temperature') # Long name
        tmp_def <- ncvar_def(paste0(tolower(names(temp_list)[i]), "_watertemp"), "Celsius", list(lon1, lat2, timedim,depthdim), fillvalue, lname, prec="float", compression = 4, shuffle = FALSE) # Define variable
        nc_vars[[i]] <- tmp_def # Add to list
      }
      names(nc_vars) <- names(temp_list) # Re-assign list names
      
      fname ='ensemble_output.nc4' # Ensemble output
     
      # Create and input data into the netCDF file
      ncout <- nc_create(fname, nc_vars, force_v4 = T)
      # Loop through and add each variable
      for(i in 1:length(temp_list)){
        mat1 <- matrix(NA, nrow = nc_vars[[i]]$dim[[3]]$len, ncol = nc_vars[[i]]$dim[[4]]$len)
        
        mat <- as.matrix(temp_list[[i]][,-1])
        
        mat1[1:nrow(mat),1:ncol(mat)] <- mat
        ncvar_put(ncout, nc_vars[[i]], mat1)
        ncvar_change_missval(ncout, nc_vars[[i]], missval = fillvalue)
      }
      nc_close(ncout) # Close netCDF file
      
      message('Finished writing NetCDF file [', Sys.time(), ']')
      
    }
    
    
  }
  
  # Set the timezone back to the original
  Sys.setenv(tz=original_tz)
  
  if(return_list){
    return(temp_list)
  }
}
